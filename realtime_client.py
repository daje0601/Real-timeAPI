"""
OpenAI Real-time API í´ë¼ì´ì–¸íŠ¸ ëª¨ë“ˆ (ê³µì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©)
"""
import asyncio
import base64
import json
import pyaudio
from openai import AsyncOpenAI
from member_db import TOOLS, execute_function

# ì˜¤ë””ì˜¤ ì„¤ì •
CHUNK = 1024
FORMAT = pyaudio.paInt16
CHANNELS = 1
SAMPLE_RATE = 24000  # Real-time APIëŠ” 24kHz ì‚¬ìš©

# ë””ë²„ê·¸ ëª¨ë“œ
DEBUG = False


class RealtimeClient:
    def __init__(self, api_key: str):
        self.client = AsyncOpenAI(api_key=api_key)
        self.connection = None
        self.audio = pyaudio.PyAudio()
        self.input_stream = None
        self.output_stream = None
        self.is_running = False
        self.is_playing = False
        self.audio_queue = asyncio.Queue()

    def start_audio_streams(self):
        """ì˜¤ë””ì˜¤ ì…ì¶œë ¥ ìŠ¤íŠ¸ë¦¼ì„ ì‹œì‘í•©ë‹ˆë‹¤."""
        self.input_stream = self.audio.open(
            format=FORMAT,
            channels=CHANNELS,
            rate=SAMPLE_RATE,
            input=True,
            frames_per_buffer=CHUNK
        )

        self.output_stream = self.audio.open(
            format=FORMAT,
            channels=CHANNELS,
            rate=SAMPLE_RATE,
            output=True,
            frames_per_buffer=CHUNK
        )

    async def send_audio(self):
        """ë§ˆì´í¬ ì…ë ¥ì„ ì „ì†¡í•©ë‹ˆë‹¤."""
        read_size = int(SAMPLE_RATE * 0.02)  # 20ms chunks

        while self.is_running:
            try:
                if self.input_stream and not self.is_playing:
                    data = self.input_stream.read(read_size, exception_on_overflow=False)
                    encoded = base64.b64encode(data).decode("utf-8")
                    await self.connection.input_audio_buffer.append(audio=encoded)

                await asyncio.sleep(0.01)
            except Exception as e:
                if self.is_running:
                    print(f"ì˜¤ë””ì˜¤ ì „ì†¡ ì˜¤ë¥˜: {e}")
                break

    async def play_audio(self):
        """ì˜¤ë””ì˜¤ íì—ì„œ ë°ì´í„°ë¥¼ ì¬ìƒí•©ë‹ˆë‹¤."""
        while self.is_running:
            try:
                audio_data = await asyncio.wait_for(self.audio_queue.get(), timeout=0.1)
                self.output_stream.write(audio_data)
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                if self.is_running:
                    print(f"ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜: {e}")

    async def handle_events(self):
        """ì„œë²„ ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        async for event in self.connection:
            if DEBUG:
                print(f"[DEBUG] Event: {event.type}")

            if event.type == "session.created":
                print("âœ“ ì„¸ì…˜ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

            elif event.type == "session.updated":
                print("âœ“ ì„¸ì…˜ ì„¤ì • ì™„ë£Œ")
                # ì´ˆê¸° ì¸ì‚¬ ìš”ì²­
                await self.send_initial_greeting()

            elif event.type == "input_audio_buffer.speech_started":
                if DEBUG:
                    print("[DEBUG] ìŒì„± ì…ë ¥ ì‹œì‘")
                self.is_playing = False
                # ì˜¤ë””ì˜¤ í ë¹„ìš°ê¸°
                while not self.audio_queue.empty():
                    try:
                        self.audio_queue.get_nowait()
                    except:
                        break

            elif event.type == "input_audio_buffer.speech_stopped":
                if DEBUG:
                    print("[DEBUG] ìŒì„± ì…ë ¥ ì¢…ë£Œ")

            elif event.type == "response.audio.delta":
                # ìŒì„± ì‘ë‹µ ìˆ˜ì‹ 
                self.is_playing = True
                audio_bytes = base64.b64decode(event.delta)
                await self.audio_queue.put(audio_bytes)

            elif event.type == "response.audio.done":
                self.is_playing = False
                # AI ì‘ë‹µ í›„ ì…ë ¥ ë²„í¼ ë¹„ìš°ê¸° (ì´ì „ ì†ŒìŒ ì œê±°)
                await self.connection.input_audio_buffer.clear()

            elif event.type == "response.created":
                # AI ì‘ë‹µ ì‹œì‘ ì‹œ ì¤„ë°”ê¿ˆ
                print("\nğŸ¤– ", end="", flush=True)

            elif event.type == "response.audio_transcript.delta":
                # AI ì‘ë‹µ í…ìŠ¤íŠ¸ ì¶œë ¥
                print(f"\033[94m{event.delta}\033[0m", end="", flush=True)

            elif event.type == "response.audio_transcript.done":
                print()  # ì¤„ë°”ê¿ˆ

            elif event.type == "conversation.item.input_audio_transcription.completed":
                # ì‚¬ìš©ì ìŒì„± ì¸ì‹ ê²°ê³¼ (ì¶œë ¥í•˜ì§€ ì•ŠìŒ)
                pass

            elif event.type == "response.function_call_arguments.done":
                await self.handle_function_call(event)

            elif event.type == "error":
                print(f"\nâŒ ì˜¤ë¥˜: {event.error.message}")
                if DEBUG:
                    print(f"   ì½”ë“œ: {event.error.code}")

    async def handle_function_call(self, event):
        """Function callingì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        call_id = event.call_id
        name = event.name
        arguments = json.loads(event.arguments)

        print(f"\nâš™ï¸  í•¨ìˆ˜ í˜¸ì¶œ: {name}")
        print(f"   ì¸ì: {arguments}")

        # í•¨ìˆ˜ ì‹¤í–‰
        result = execute_function(name, arguments)
        print(f"   ê²°ê³¼: {result}")

        # ê²°ê³¼ ì „ì†¡
        await self.connection.conversation.item.create(
            item={
                "type": "function_call_output",
                "call_id": call_id,
                "output": json.dumps(result, ensure_ascii=False)
            }
        )

        # ì‘ë‹µ ìƒì„± ìš”ì²­
        await self.connection.response.create()

    async def send_initial_greeting(self):
        """AIê°€ ë¨¼ì € ì¸ì‚¬í•˜ë„ë¡ ìš”ì²­í•©ë‹ˆë‹¤."""
        print("\nğŸ¤ ë§ì”€í•´ ì£¼ì„¸ìš”. (ì¢…ë£Œ: Ctrl+C)\n")

        # AIê°€ ë¨¼ì € ì¸ì‚¬í•˜ë„ë¡ ì‘ë‹µ ìƒì„± ìš”ì²­
        await self.connection.response.create()

    async def run(self):
        """í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        self.is_running = True

        try:
            print("ğŸ”— API ì—°ê²° ì¤‘...")

            async with self.client.beta.realtime.connect(
                model="gpt-realtime"
            ) as conn:
                self.connection = conn
                print("âœ“ API ì—°ê²° ì™„ë£Œ")

                # ì„¸ì…˜ ì„¤ì •
                await conn.session.update(
                    session={
                        "modalities": ["text", "audio"],
                        "instructions": """ë‹¹ì‹ ì€ TEST FAQë¥¼ ë‹´ë‹¹í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.
ì²˜ìŒ ì¸ì‚¬í•  ë•Œ "ì•ˆë…•í•˜ì„¸ìš”, TEST FAQë¥¼ ë‹´ë‹¹í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"ë¼ê³  ë§í•˜ì„¸ìš”.

íšŒì› íƒˆí‡´ë¥¼ ì›í•˜ëŠ” ê²½ìš° ë‹¤ìŒ ì ˆì°¨ë¥¼ ë”°ë¥´ì„¸ìš”:
1. ë¨¼ì € íšŒì›ë‹˜ì˜ ì„±í•¨ì„ ì—¬ì­¤ë´…ë‹ˆë‹¤.
2. search_member_by_name í•¨ìˆ˜ë¡œ íšŒì› ì¡´ì¬ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
3. ë³¸ì¸ ì¸ì¦ì„ ìœ„í•´ ì „í™”ë²ˆí˜¸ ë’· 4ìë¦¬ì™€ ìƒë…„ì›”ì¼ì„ ì—¬ì­¤ë´…ë‹ˆë‹¤.
4. verify_member í•¨ìˆ˜ë¡œ ë³¸ì¸ ì¸ì¦ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
5. ì¸ì¦ ì„±ê³µ ì‹œ, íƒˆí‡´ ì‚¬ìœ ë¥¼ ì—¬ì­¤ë³´ê³  process_withdrawalë¡œ íƒˆí‡´ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.

ì£¼ì˜ì‚¬í•­:
- ë°˜ë“œì‹œ ë³¸ì¸ ì¸ì¦ì„ ì™„ë£Œí•œ í›„ì—ë§Œ íƒˆí‡´ë¥¼ ì§„í–‰í•˜ì„¸ìš”.
- ìƒë…„ì›”ì¼ì€ 8ìë¦¬ ìˆ«ìë¡œ ë°›ì•„ì£¼ì„¸ìš” (ì˜ˆ: 19900515)
- ì¹œì ˆí•˜ê³  ê³µì†í•œ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
- í•œêµ­ì–´ë¡œ ëŒ€í™”í•˜ì„¸ìš”.
- ì§§ê³  ê°„ê²°í•˜ê²Œ ì‘ë‹µí•˜ì„¸ìš”.""",
                        "voice": "alloy",
                        "input_audio_format": "pcm16",
                        "output_audio_format": "pcm16",
                        "input_audio_transcription": {
                            "model": "whisper-1"
                        },
                        "turn_detection": {
                            "type": "server_vad",
                            "threshold": 0.95,  # 0.0~1.0, ê±°ì˜ ìµœëŒ€ì¹˜
                            "prefix_padding_ms": 200,
                            "silence_duration_ms": 1200  # ë§ ëë‚œ í›„ ëŒ€ê¸° ì‹œê°„
                        },
                        "tools": TOOLS
                    }
                )

                # ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì‹œì‘
                self.start_audio_streams()

                # íƒœìŠ¤í¬ ì‹¤í–‰
                await asyncio.gather(
                    self.send_audio(),
                    self.play_audio(),
                    self.handle_events()
                )

        except KeyboardInterrupt:
            print("\n\ní”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        except Exception as e:
            print(f"\nì—°ê²° ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
        finally:
            await self.cleanup()

    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤."""
        self.is_running = False

        if self.input_stream:
            self.input_stream.stop_stream()
            self.input_stream.close()

        if self.output_stream:
            self.output_stream.stop_stream()
            self.output_stream.close()

        self.audio.terminate()
